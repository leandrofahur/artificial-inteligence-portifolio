{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89d2d46b-b370-4c0f-be49-a923ae981a84",
   "metadata": {},
   "source": [
    "# **Multivariate Linear Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2def5747-69fe-4be2-b860-4c6cff0268f9",
   "metadata": {},
   "source": [
    "#### **The Model:**\n",
    "\n",
    "Lets denote the multivariate model by a model expressed as $f_{\\vec{w},b}(\\mathbf{X})$\n",
    "\n",
    "- $\\mathbf{X}$ is a $m x n$ matrix where $m$ is the number of samples and $n$ is the number of features.\n",
    "\n",
    "$$\n",
    "\\mathbf{X} =\n",
    "\\begin{bmatrix}\n",
    "x_{1,1} & x_{1,2} & \\cdots & x_{1,n} \\\\\n",
    "x_{2,1} & x_{2,2} & \\cdots & x_{2,n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{m,1} & x_{m,2} & \\cdots & x_{m,n} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- $\\vec{w}$ is the vector of weights.\n",
    "\n",
    "$$\n",
    "\\vec{w} =\n",
    "\\begin{bmatrix}\n",
    "w_{1} \\\\\n",
    "w_{2} \\\\\n",
    "\\vdots \\\\\n",
    "w_{m} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- $b$ is known as bias.\n",
    "\n",
    "Therefore, the model:\n",
    "\n",
    "$$f_{\\vec{w},b}(\\mathbf{X}) = \\mathbf{X} \\vec{w} + b \\tag{1}$$\n",
    "\n",
    "<br />\n",
    "\n",
    "#### **The Cost function:**\n",
    "\n",
    "$$ J(\\vec{w}, b) = \\frac{1}{m} \\mathbf{X}^T (\\mathbf{X} \\vec{w} + b - \\vec{y}) \\tag{2}$$\n",
    "\n",
    "- $\\mathbf{X}^T$ is the feature matrix transposed.\n",
    "- $\\vec{y}$ is the target vector.\n",
    "\n",
    "$$\n",
    "\\vec{y} =\n",
    "\\begin{bmatrix}\n",
    "y_{1} \\\\\n",
    "y_{2} \\\\\n",
    "\\vdots \\\\\n",
    "y_{m} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "<br/>\n",
    "\n",
    "#### **The the Gradient:**\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial \\vec{w}} = \\frac{1}{m} \\mathbf{X}^T (\\mathbf{X} \\vec{w} + b - \\vec{y}) \\tag{3}$$\n",
    "$$\\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^{m} (\\mathbf{X} \\vec{w} + b - \\vec{y})\n",
    " \\tag{4}$$\n",
    "\n",
    "\\begin{align}\n",
    "w = w - \\alpha \\frac{\\partial J(w,b)}{\\partial w} \\tag{5}\\\\\n",
    "b = b - \\alpha \\frac{\\partial J(w,b)}{\\partial b} \\tag{6}\\\\\n",
    "\\end{align}\n",
    "\n",
    "**Conventions:**\n",
    "- The naming of python variables containing partial derivatives follows this pattern,$\\frac{\\partial J(w,b)}{\\partial b}$  will be `dj_db`.\n",
    "- w.r.t is With Respect To, as in partial derivative of $J(\\vec{w},b)$ With Respect To $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99db63f6-a755-4223-b921-a94a1a4a97ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary pkgs:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e205aa1-dd65-42cd-a70b-759e25c8fb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateLinearRegression:\n",
    "    def __init__(self, learning_rate=0.01, epochs=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.cost_history = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        m, n = X.shape\n",
    "        self.weights = np.zeros(n)\n",
    "        self.bias = 0\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            y_pred = self.predict(X)\n",
    "            dj_dw = (1/m) * np.dot(X.T, (y_pred - y))\n",
    "            dj_db = (1/m) * np.sum(y_pred - y)\n",
    "            \n",
    "            self.weights -= self.learning_rate * dj_dw\n",
    "            self.bias -= self.learning_rate * dj_db\n",
    "            \n",
    "            cost = self.cost_function(X, y)\n",
    "            self.cost_history.append(cost)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias\n",
    "\n",
    "    def cost_function(self, X, y):\n",
    "        m = len(y)\n",
    "        y_pred = self.predict(X)\n",
    "        cost = (1/(2*m)) * np.sum((y_pred - y)**2)\n",
    "        return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97d9e7de-ae97-4949-8107-b8cc95c3d551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the California housing dataset:\n",
    "housing = fetch_california_housing()\n",
    "X = housing.data\n",
    "y = housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f794026a-d2de-4035-8bb4-fff3fef925b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the dataset:\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b15eefd-20dc-48f2-a203-06c3c2eb4c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into features and target:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87377177-c932-4aa2-ab79-0fbec16696a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [3.08698327 1.13548264 2.3254224 ]\n",
      "Bias: 3.2641322820333336\n"
     ]
    }
   ],
   "source": [
    "model = MultivariateLinearRegression(learning_rate=0.01, epochs=1000)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(f\"Weights: {model.weights}\")\n",
    "print(f\"Bias: {model.bias}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "08409f91-6cb1-4a65-8cbf-8c780130c404",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 15) (1523342833.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[41], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    plt.title('Actual vs Predicted values\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 15)\n"
     ]
    }
   ],
   "source": [
    "# plotting the cost function over iterations:\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(model.epochs), model.cost_history, 'b-')\n",
    "plt.title('Cost Function Over Iterations')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()\n",
    "\n",
    "# plotting Actual vs Predicted values:\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(y_test, predictions, c='r')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'b--', lw=2)\n",
    "plt.xlabel('Actual values')\n",
    "plt.ylabel('Predicted values')\n",
    "plt.title('Actual vs Predicted values\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac04c3a6-546f-45f0-83e5-0cfdf4c0d4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
